# -*- coding: utf-8 -*-
"""CNN_MNIST_TF

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LvaOAKYA3e0dfKdKdQEeyV8KrEPKpQ8g

# Import Library
"""

import tensorflow as tf
from keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout
from keras import Sequential
from keras import optimizers
import tensorflow.nn as nn
import numpy as np
import matplotlib.pyplot as plt

device = tf.test.gpu_device_name()

if device != '/device:GPU:0':
  raise SystemError('GPU device not found')

print('Found GPU at: {}'.format(device))

"""# valriable setting"""

batch_size_train = 64
batch_size_val = 64
batch_size_test = 1000

learning_rate = 0.01

"""# Data load & reshaping & normalization"""

mnist_data = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist_data.load_data()

x_train = x_train.reshape(len(x_train), 28, 28, 1)
x_test = x_test.reshape(len(x_test), 28, 28, 1)

x_train, x_test = x_train / 255.0, x_test / 255.0

print(len(x_train), len(x_test))

"""## Data Check"""

plt.figure(figsize=(10, 10))

for c in range(16):
  plt.subplot(4, 4, c+1)
  plt.imshow(x_train[c].reshape(28, 28), cmap='gray')

plt.show()
print(y_train[:16])

"""# Modeling"""

model = Sequential([
    Conv2D(input_shape=(28, 28, 1), kernel_size=3, filters=32),
    MaxPool2D(strides=2),
    Conv2D(kernel_size=3, filters=64),
    MaxPool2D(strides=2),
    Conv2D(kernel_size=3, filters=128),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(10, activation='softmax')
])

model.compile(optimizer=optimizers.Adam(),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""## Training"""

history = model.fit(x_train, y_train, epochs=10, validation_split=0.25)

"""# Evaluation"""

plt.figure(figsize=(12,4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], 'b-', label='loss')
plt.plot(history.history['val_loss'], 'r--', label='val_loss')
plt.xlabel('Epoch')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], 'g-', label='accuracy')
plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')
plt.xlabel('Epoch')
plt.ylim(0.7, 1)
plt.legend()

plt.show()

eval = model.evaluate(x_test, y_test)

print("Accuracy : %0.4f" %eval[1])